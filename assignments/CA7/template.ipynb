{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Updates"
      ],
      "metadata": {
        "id": "heYH1BlB1mju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!pip install -U accelerate"
      ],
      "metadata": {
        "id": "ONNtt9CX1qx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After updating packages, restart the session and then start your notebook from imports."
      ],
      "metadata": {
        "id": "gjZJoIqa2EQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "2uPmxwGH1wkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "-x-7uyX61y2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "HJaPnJzZ135z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ARGS = {\n",
        "    'Name': 'microsoft/Phi-3-mini-128k-instruct',\n",
        "    'DType': bfloat16\n",
        "}"
      ],
      "metadata": {
        "id": "n6HjpYYR1Ifa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcM3KTch04SM"
      },
      "outputs": [],
      "source": [
        "def load_model(model_args):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_args['Name'],\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.model_args['DType'],\n",
        "        low_cpu_mem_usage=True,\n",
        "        device_map={\"\": device},\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_args['Name'],\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good luck :)"
      ],
      "metadata": {
        "id": "adZV4H9u2sjx"
      }
    }
  ]
}